---
title: Challenge Infrastructure
layout: article
excerpt: Learn how to set-up the wireframe of a challenge. 
category: howto
---


## Challenge Guide Overview

This guide is meant to help organizers create a **challenge space** within Synapse to host a crowd-sourced challenge.  This space gives participants a place to learn about the challenge, join the challenge community, submit entries, track their progress and view results.  This document will focus on:

* Creating the challenge space
* Configurating the challenge space
* Interacting with the submitted entries


## Create a Challenge Space

All the steps below will be completed by using the `createchallenge` command in the challengeutils python package.  The instructions on to install and use this package can be found on the on this [page](https://github.com/Sage-Bionetworks/challengeutils).  This following describes the key Synapse components generated by the tool above.


### Challenge Projects

The command `createchallenge` creates two Synapse projects:

- **Live challenge project.** The 'live' challenge project will have two purposes.  During the development of the challenge, it will serve as the pre-registration page for participants to learn about the challenge.  Once the challenge is ready to be launched, the pre-registration page will be replaced with a challenge wiki that will allow participants to register for the challenge.  The wiki will also include detailed information about the challenge questions, data, participation, evaluation metrics, etc.
- **Staging challenge project.** This project is used by the organizers during the development of the challenge to share files and draft the challenge wiki.

For background on how to create and share Projects, Files, Folders and Wiki pages, please see our article [Making a Project](/articles/making_a_project.html).


### Synapse Teams

The command `createchallenge` creates three Synapse Teams:

* **Challenge participant team.** This Synapse Team will include the individual participants and teams that register to the challenge.

* **Challenge administrator team.** The challenge organizers must be added to this list. This allows organizers to share files and edit the content of the wiki on the staging project, for example.

* **Challenge pre-registration team** - This team is recommended for when the challenge is under development.  It allows participants to join a mailing list to receive notification of challenge launch news.

Please visit this [page](/articles/teams.html) to learn more about teams.


### Activating Challenge Configuration

The command `createchallenge` will enable the challenge configuration for the `live challenge project`.  It will also connect the `challenge participant team` created above to this challenge project.  This will effectively enable participants to make submissions.


## Configure a Challenge Space


### Edit Wiki of Live Challenge Project

The command `createchallenge` initializes the wiki of the live challenge project with the a pre-registration page.   Organizers have to fill in the content of this page to provide information about the challenge.  The page has to made public so that anyone can learn about the challenge and pre-register.


### Edit Wiki of Staging Challenge Project

The command `createchallenge` initializes the wiki of the staging challenge project with the [DREAM Challenge Wiki Template](https://www.synapse.org/#!Synapse:syn18058986/wiki/). 

The reason two projects were created was that challenge organizers have found it convenient to continuously edit content in the staging challenge project wiki before publishing the content to the live challenge project.

{% include important.html content="All edits and changes should be made on the staging site." %}


### Deploy the Staging Wiki

The initial deployment of the staging wiki to the live challenge project must be performed with the `copyWiki` command provided by [synapseutils](https://github.com/Sage-Bionetworks/synapsePythonClient).  The wiki of the live project will be replaced by the wiki in the staging project.  

After the initial deployment, the `mirrorwiki` command provided by [challengeutils](https://github.com/Sage-Bionetworks/challengeutils) must be used to mirror the wiki from the staging site to the live site.


### Upload Challenge Data

Once the challenge data (ie. training dataset, scoring data...) are ready to be shared with the participants, they must be uploaded to the live challenge project.  

For background on how to create and share Projects, Files, Folders and Wiki pages, please see our article [Making a Project](/articles/making_a_project.html).


#### Adding Conditions for Use

Please view this [page](/articles/access_controls.html) to learn how to add conditions for use on the data.

Synapse has the ability to apply access restrictions to sensitive data (e.g. human data), so that legal requirements are met before participants access such data.  If human data are being used in the challenge, or if you have any question about sensitivity of the challenge data, please contact the Synapse Access and Compliance Team (act@sagebase.org) for support to ensure that the necessary data access approval procedure are put in place. 

There are cases in which there are no human data concerns but for which a pop-up agreement needs to be presented before download data for the first time.  Contact the Access and Compliance Team to set up this agreement. 


### Create an Evaluation Queue for Submissions

Challenge participants can submit Synapse Entities (eg. File, Folder, Project, Docker) to evaluation queues.  Challenges will often ask participants to address more than one question.  Multiple Evaluation queues should be created to support this.

Please visit the [Evaluation Queue article](/articles/evaluation_queues.html) to learn about queues.


## Interacting with Submissions

Throughout the challenge, participants will continuously submit to the evaluation queues.  Organizers should deploy an automated job that will continuously validate and score participant submissions.  The `status` of a submission can be stored to the submission status and annotations, such as `score`, can also be added. To learn more about interacting with submissions, please take a closer look at this list of [commands](https://python-docs.synapse.org/build/html/index.html#evaluations).  


### Revealing Submissions and Scores

When organizers are ready to reveal scores to participants, they can create a leaderboard. Leaderboards are sorted, paginated, tabular forms that display submission annotations (such as scores from your scoring application and other metadata). They are dynamic and update as annotations/scores change, so can provide real-time insight into how your challenge is going. 

Learn more about adding leaderboards in the [Evaluation Queue article](/articles/evaluation_queues.html)


