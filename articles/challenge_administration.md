---
title: Challenge Infrastructure
layout: article
excerpt: Learn how to set-up the wireframe of a challenge. 
category: howto
---


## Challenge Guide Overview

This guide is meant to help organizers create a **challenge space** within Synapse to host a crowd-sourced challenge.  This space gives participants a place to learn about the challenge, join the challenge community, submit entries, track their progress and view results.  This document will focus on:

* Creating the challenge space
* Configurating the challenge space
* Interacting with the submitted entries


## Create a Challenge Space

All the steps below will be completed by using the `createchallenge` command in the challengeutils python package.  The instructions on to install and use this package can be found on the on this [page](https://github.com/Sage-Bionetworks/challengeutils).  This following describes the key Synapse components generated by the tool above.


### Challenge Projects

The command `createchallenge` creates two Synapse projects:

- **Live challenge project.** The 'live' challenge project will have two purposes.  During the development of the challenge, it will serve as the pre-registration page for participants to learn about the challenge.  Once the challenge is ready to be launched, the pre-registration page will be replaced with a challenge wiki that will allow participants to register for the challenge.  The wiki will also include detailed information about the challenge questions, data, participation, evaluation metrics, etc.
- **Staging challenge project.** This project is used by the organizers during the development of the challenge to share files and draft the challenge wiki.

For background on how to create and share Projects, Files, Folders and Wiki pages, please see our article [Making a Project](/articles/making_a_project.html).


### Synapse Teams

The command `createchallenge` creates three Synapse Teams:

* **Challenge participant team.** This Synapse Team will include the individual participants and teams that register to the challenge.

* **Challenge administrator team.** The challenge organizers must be added to this list. This allows organizers to share files and edit the content of the wiki on the staging project, for example.

* **Challenge pre-registration team** - This team is recommended for when the challenge is under development.  It allows participants to join a mailing list to receive notification of challenge launch news.

Please visit this [page](/articles/teams.html) to learn more about teams.


### Activating Challenge Configuration

The command `createchallenge` will enable the challenge configuration for the `live challenge project`.  It will also connect the `challenge participant team` created above to this challenge project.  This will effectively enable participants to make submissions.


## Configure a Challenge Space


### Edit Wiki of Live Challenge Project

The command `createchallenge` initializes the wiki of the live challenge project with the a pre-registration page.   Organizers have to fill in the content of this page to provide information about the challenge.  The page has to made public so that anyone can learn about the challenge and pre-register.


### Edit Wiki of Staging Challenge Project

The command `createchallenge` initializes the wiki of the staging challenge project with the [DREAM Challenge Wiki Template](https://www.synapse.org/#!Synapse:syn18058986/wiki/). 

The reason two projects were created was that challenge organizers have found it convenient to continuously edit content in the staging challenge project wiki before publishing the content to the live challenge project.

{% include important.html content="All edits and changes should be made on the staging site." %}


### Deploy the Staging Wiki

The initial deployment of the staging wiki to the live challenge project must be performed with the `copyWiki` command provided by [synapseutils](https://github.com/Sage-Bionetworks/synapsePythonClient).  The wiki of the live project will be replaced by the wiki in the staging project.  

After the initial deployment, the `mirrorwiki` command provided by [challengeutils](https://github.com/Sage-Bionetworks/challengeutils) must be used to mirror the wiki from the staging site to the live site.


### Upload Challenge Data

Once the challenge data (ie. training dataset, scoring data...) are ready to be shared with the participants, they must be uploaded to the live challenge project.  

For background on how to create and share Projects, Files, Folders and Wiki pages, please see our article [Making a Project](/articles/making_a_project.html).


#### Adding Conditions for Use

Please view this [page](/articles/access_controls.html) to learn how to add conditions for use on the data.

Synapse has the ability to apply access restrictions to sensitive, human data, so that legal requirements are met before participants access such data.  If human are being used in the challenge, or if you have any question about sensitivity of the challenge data, you must contact the Synapse Access and Compliance Team (act@sagebase.org) who will help put in place the necessary data access approval procedure.  

There are cases in which there are no human data concerns but for which a pop-up agreement needs to be presented before download data for the first time.  Contact the Access and Compliance Team to set up this agreement. 


### Create an Evaluation Queue for Submissions

Challenge participants can submit Synapse Entities (eg. File, Folder, Project, Docker) to evaluation queues.  Challenges will often ask participants to address more than one question.  Multiple Evaluation queues should be created to support this.

Please visit the [Evaluation Queue article](/articles/evaluation_queues.html) to learn about queues.


## Interacting with Submissions

Every submission has a unique submission id, this should not be confused with synapse ids which start with `syn`.  A submission can also contain annotations that can be used to display on live leaderboards.  It is good to note that these added annotations can be set to either public or private.  Private annotations cannot be read by people on the live leaderboard unless the READ_PRIVATE_SUBMISSIONS ACL is set on the evaluation queue.  Learn more about submissions in the [Evaluation Queue article](/articles/evaluation_queues.html)

{% tabs %}
	{% tab Python %}
		{% highlight python %}
#Get submission / annotations
sub = syn.getSubmission(submissionId)
annotations = syn.getSubmissionStatus(submissionId)
#Get all scored submissions in an evaluation queue
e = syn.getEvaluation(e)
bundles = syn.getSubmissionBundles(e, status = "SCORED")
for sub, status in bundles:
	#validate submission
	#score submission
	print(sub)
	print(status)
		{% endhighlight %}
	{% endtab %}

	{% tab R %}
		{% highlight r %}
# Get submission / annotations
sub <- synGetSubmission(submissionId)
annotations <- synGetSubmissionStatus(submissionId)
# Get all scored submissions in an evaluation queue
bundles <- as.list(synGetSubmissionBundles(evaluation, status="SCORED"))
		{%endhighlight %}
	{% endtab %}
{% endtabs %}


### Revealing Submissions and Scores

To reveal submissions of a challenge, organizers can create a leaderboard. Leaderboards are sorted, paginated, tabular forms that display submission annotations (such as scores from your scoring application and other metadata). Leaderboards are dynamic and update as annotations/scores change, so can provide real-time insight into how your Challenge is going. The scoring application templates mentioned above print out valid sample widget text suitable for pasting into the wiki editor.  In the "Challenge Admin" control, described above, you provide "Can View" access to whomever you wish to be able to see the leaderboard. 

To add a leaderboard to your Challenge Wiki,
* First go to the Challenge Project and get the ID of the Evaluation of interest; Challenges can have multiple evaluations so it's important to identify which evaluation you want to summarize.
* Next, edit the wiki page where you want to add your leaderboard and choose "Insert" and then "Leaderboard". 
* Finally, you'll configure your leaderboard by entering a query of the form "Select * from Evaluation_12345" where 12345 is the ID from the first step. 

<br>If you have some annotations already then you can click "Refresh Columns" to add display columns for the existing annotations. Otherwise you have to add the columns manually. You can reorder the columns and choose what to sort by. Keep in mind that "private" annotations will not be visible to participants (only to challenge administrators). 

